# -中国移动运营分析实时监控平台
1.项目背景
中国移动公司旗下拥有很多的子机构,基本可以按照省份划分. 而各省份旗下的充值机构也非常的多.
目前要想获取整个平台的充值情况,需要先以省为单元,进行省份旗下的机构统计,然后由下往上一层一层的统计汇总,过程太过繁琐,且统计周期太长. 且充值过程中会涉及到中国移动信息系统内部各个子系统之间的接口调用, 接口故障监控也成为了重点监控的内容之一.(动态的，实时的全国性的XX  这里以身份为例)
为此建设一个能够实时监控全国的充值情况的平台, 掌控全网的实时充值, 各接口调用情况意义重大.
2.	技术选型（头脑风暴）
2.1.	难点分析
	1）移动公司旗下子充值机构众多, 充值数据
	2）数据实时性要求高
2.2.	可用技术选型
1）实时流式计算框架 Storm
2）实时流式计算框架 Spark Streaming
3）实时流式计算框架 Flink

2.3.	对比分析
Storm、Spark streaming、Flink 都是开源的分布式系统，具有低延迟、可扩展和容错性诸多优点，允许你在运行数据流代码时，将任务分配到一系列具有容错能力的计算机上并行运行,都提供了简单的 API 来简化底层实现的复杂程度。




Apache Storm
在 Storm 中，先要设计一个用于实时计算的图状结构，我们称之为拓扑（topology）。这个拓扑将会被提交给集群，由集群中的主控节点（master node）分发代码，将任务分配给工作节点（worker node）执行。一个拓扑中包括 spout 和 bolt 两种角色，其中 spout 发送消息，负责将数据流以 tuple 元组的形式发送出去；而 bolt 则负责转换这些数据流，在 bolt 中可以完成计算、过滤等操作，bolt 自身也可以随机将数据发送给其他 bolt。由 spout 发射出的 tuple是不可变数组，对应着固定的键值对。  

（说出Spout和Bolt的概念，Spout发送的数据是以元组的形式发送出去的，Spout发送数据可以发送n多个Bolt,Bolt里面的数据还可以送往其他的Bolt）

Apache Spark
Spark Streaming 是核心 Spark API 的一个扩展，它并不会像 Storm 那样一次一个地处理数据流，而是在处理前按时间间隔预先将其切分为一段一段的批处理作业。Spark 针对持续性数据流的抽象称为 DStream（DiscretizedStream），一个 DStream 是一个微批处理（micro-batching）的 RDD（弹性分布式数据集）；而 RDD 则是一种分布式数据集，能够以两种方式并行运作， 分别是任意函数和滑动窗口数据的转换。
(这个项目是结合的sparkStream+redis达到实时统计)




Apache Flink
Flink 是一个针对流数据和批数据的分布式处理引擎。它主要是由 Java 代码实现。对 Flink 而言，其所要处理的主要场景就是流数据，批数据只是流数据的一个极限特例而已。再换句话说，Flink 会把所有任务当成流来处理，这也是其最大的特点。Flink 可以支持本地的快速迭代，以及一些环形的迭代任务。并且 Flink 可以定制化内存管理。在这点，如果要对比 Flink 和 Spark 的话，Flink 并没有将内存完全交给应用层。这也是为什么 Spark 相对于 Flink，更容易出现 OOM 的原因（out of memory）。就框架本身与应用场景来说，Flink 更相似与
Storm。
 
3、项目架构
（关注的问题：数据在哪里，拿到之后放在哪里
Spark Streaming  从哪里那数据   拿完数据存在哪    存完之后怎么处理  是给谁使用的
）

(大概有23台台服务器，每一台结点都会装flume，每一台结点上都有日志，采集信息使用tail -F来采集的。日志数据格式json的格式，区分业务   pc端（服务器  tomcat 浏览器 发送http请求  tomcat所在服务器，服务器上安装flume,tail -f 的source 采集数据   送往kafka的集群，kafka的主题叫JsonData  ）的和手机端(微信，支付宝等等其他的APP到此服务器上)的日志服务器不同。还有四台结点（支付结果，充值结果通知的结点）所有的不同来源的日志数据都会通过Flume采集到我们的kafka里面，kafka里面有一个主题叫做jsonData主题，通过spark streaming对接数据或者拉取数据进行相应的流式处理，处理完的结果存入redis的数据库，将来做监控。通过可视化的界面显示。
这里需要手动的维护偏移量，保存到mysql的数据库，注意偏移量要自己维护，可视化采用的echars)



什么是支付通知：（调用的支付接口的实现界面）到支付宝或者微信，银联的支付界面叫支付通知

什么是充值结果通知：扫码扣钱的实现才是（真正的支付）。

73 到 76 主机，每台主机上面部署了 6 个 server, 2 个负责支付结果通知，2 个负责发起充值请求，2 个负责充值结果通知.目前退费没有监控

4、集群规模--Flume
4.1、业务节点分为 PC 端和手机端:
PC 端一共有 11 台, flume 会监控每台节点生成的日志文件, 一共有 11 个 Flume 节点手机端一共有 8 台,flume 会监控每台节点生成的日志文件,  一共有 8 个 Flume 节点.
4.2、支付结果通知和充值结果通知:
该业务有 4 台节点, flume 会监控每台节点生成的日志文件, 一共有 4 个 Flume 节点. 机器配置?：说不知道也行
（多少核 多大内存  ）

5、项目数据量
1):数据量每天大概 2000 到 3000 万笔的下单量, 每条数据大概在 0.5KB 左右,下单量数据大概在 15GB 左右.
2):最后充值成功的大概 500 到 1000 万,平时充值成功的大概五六百万笔.
3):峰值:月初和月末量比较大
6、项目需求
6.1、业务概况
统计全网的充值成功订单量,  充值金额,  充值成功率及充值平均时长.
实时充值业务办理趋势, 主要统计全网的订单量数据和成功率.

6.2、业务质量
6.2.1、全国各省充值业务失败量分布
统计每个省份的充值失败数据量, 并以地图的方式显示分布情况.



6.3、业务体验
6.3.1、支付
6.3.1.1、最大时长---统计支付订单的最大时长.
6.3.2.2、最小时长---统计支付订单的最小时长.

6.3.2、充值
6.3.2.1、平均时长---统计充值订单的平均时长.
6.3.2.2、最大时长---统计充值订单的最大时长.
6.3.2.3、最小时长---统计充值订单的最小时长.
6.4、实时充值情况分布
实时统计每分钟的充值笔数和充值金额


7、数据说明：
充值的整个过程是包括：

订单创建->支付请求->支付通知->充值请求->充值通知

而我们需要处理的就是充值通知部分的数据。而我们的数据中是包含上面这五种类型的数据的。

那么我们如何从那么多数据中确定哪条数据是充值通知的数据呢？

我们可以通过serviceName字段来确定，如果该字段是reChargeNotifyReq则代表该条数据是充值通知部分的数据。

数据展示：


单条数据所有字段：


8、业务需求分析
充值订单量我们只需要通过有多少行数就可以确定有多少笔。
对于充值金额，我们首先需要确定到充值成功的订单数（字段bussinessRst如果为0000则代表成功）
找到充值成功的订单之后，我们可以将该数据的chargefee字段进行累加。就可以得到总金额。
充值成功率：我们只要知道总交易笔数和成功的笔数即可求。
充值平均时长：首先我们需要知道开始时间和结束时间，我们才能知道充值所花费的时间。
开始时间:对于开始时间，这里有一个RequestId字段，它是由时间戳+随机数生成的。
结束时间：即为接到充值通知的时间，为字段（receiveNotifyTime）
对于业务失败量的分布，首先我们需要知道在哪个省份，哪个地区。
我们可以根据provinceCode字段来确定省份
对于失败的订单我们可以通过统计bussinessRst为不是0000的情况来确定。
